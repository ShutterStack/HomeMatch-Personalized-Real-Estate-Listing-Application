{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## HomeMatch: Personalized Real Estate Listing Application\n",
        "Developed by: ShutterStack [Arya Patil]\n",
        "\n",
        "\n",
        "\n",
        "Organization: Future Homes Realty (Simulated)\n",
        "\n",
        "Overview:\n",
        "\n",
        "HomeMatch is an innovative Python application designed to revolutionize the real estate search experience by delivering personalized property listings tailored to individual buyer preferences. Leveraging the power of large language models (LLMs) via the Groq API, LangChain for prompt management, and ChromaDB for vector-based semantic search, HomeMatch transforms standard listings into engaging, buyer-specific narratives. This end-to-end solution generates a dataset of real estate listings, stores them in a vector database, processes buyer preferences, performs semantic searches, and outputs personalized descriptions—all within a modular, step-by-step workflow."
      ],
      "metadata": {
        "id": "ezaqE0qTlz7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1: Setup and Dependencies\n",
        "**Purpose:** This cell prepares the environment for the HomeMatch application by installing necessary Python packages and configuring core components.  \n",
        "**What Happens:**  \n",
        "- Installs dependencies including LangChain, Groq API client, ChromaDB, HuggingFace embeddings, and pandas using pip.  \n",
        "- Imports required Python libraries for file handling (json, csv), regular expressions (re), UUID generation (uuid), and the core AI tools (LangChain, Groq, ChromaDB).  \n",
        "- Configures the Groq LLM with the `llama3-70b-8192` model, setting an API key (to be replaced by the user), temperature for response creativity, and maximum token limit.  \n",
        "- Initializes the HuggingFace embedding model (`all-MiniLM-L6-v2`) for vectorizing listing data.  \n",
        "- Sets up a persistent ChromaDB client at `/tmp/chroma` for storing listing embeddings, with a collection name `real_estate_listings`.  \n"
      ],
      "metadata": {
        "id": "5VLMgbuLmUP3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QMFntTsOd_sV"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-groq langchain-chroma chromadb huggingface-hub sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjhyicl_feGK",
        "outputId": "fbe19296-772c-49ea-fe33-00f3ea82f193"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.47)\n",
            "Collecting langchain<1.0.0,>=0.3.21 (from langchain-community)\n",
            "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain<1.0.0,>=0.3.21->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.6\n",
            "    Uninstalling langchain-text-splitters-0.3.6:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.6\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.20\n",
            "    Uninstalling langchain-0.3.20:\n",
            "      Successfully uninstalled langchain-0.3.20\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.21 langchain-community-0.3.20 langchain-text-splitters-0.3.7 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0ADRaAFeRjB",
        "outputId": "9a06f611-09f7-49d3-e3ed-60c9db73b2fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "The token `lang` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `lang`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "import csv\n",
        "import uuid\n",
        "import re\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import chromadb\n",
        "\n",
        "# Configure LLM with API key (replace with your actual Groq API key)\n",
        "GROQ_API_KEY = \"YOUR_GROQ_API_KEY\"  # Replace this!\n",
        "llm = ChatGroq(\n",
        "    api_key=GROQ_API_KEY,\n",
        "    model_name=\"llama3-70b-8192\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=2000\n",
        ")\n",
        "\n",
        "# Configure embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize ChromaDB\n",
        "client = chromadb.PersistentClient(path=\"/tmp/chroma\")\n",
        "collection_name = \"real_estate_listings\"\n",
        "\n",
        "print(\"Dependencies installed and configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg3nyzpcfAnJ",
        "outputId": "5903b8a6-09a8-43ce-da28-b44c380a619b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed and configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2: Generate Listings\n",
        "**Purpose:** This cell generates a dataset of 10 unique real estate listings and saves them in both JSON and CSV formats for later use.  \n",
        "**What Happens:**  \n",
        "- Defines a `ListingGenerator` class with methods to generate, parse, and save listings.  \n",
        "- Uses the LLM to generate 10 diverse listings based on a structured prompt, specifying fields like neighborhood, price, bedrooms, bathrooms, house size, description, and neighborhood description.  \n",
        "- Parses the LLM output using regex to extract structured data into a list of dictionaries, handling potential errors gracefully.  \n",
        "- If fewer than 10 listings are generated (due to parsing issues or LLM failure), supplements with fallback sample listings, ensuring exactly 10 unique entries.  \n",
        "- Saves the listings to `listings.json` (human-readable format) and `listings.csv` (tabular format) in the Colab file system.  \n",
        "- Prints progress messages, including the number of listings generated and confirmation of file saves.  \n"
      ],
      "metadata": {
        "id": "_EKlp-lnmbsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ListingGenerator:\n",
        "    def __init__(self):\n",
        "        self.listings = []\n",
        "\n",
        "    def generate_listings(self, num_listings=10):\n",
        "        \"\"\"Generate diverse real estate listings\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"\"\"Generate {num_listings} unique real estate listings. For each:\n",
        "\n",
        "            --- LISTING START ---\n",
        "            Neighborhood: [Unique name]\n",
        "            Price: [$200,000-$2,000,000]\n",
        "            Bedrooms: [2-6]\n",
        "            Bathrooms: [1-5]\n",
        "            House Size: [1,000-5,000 sqft]\n",
        "\n",
        "            Description: [200-300 character detailed description of unique features]\n",
        "\n",
        "            Neighborhood Description: [150-200 character description of community and amenities]\n",
        "            --- LISTING END ---\n",
        "\n",
        "            Ensure diversity in price, location type (urban/suburban/rural), style, and amenities.\"\"\"\n",
        "        )\n",
        "\n",
        "        chain = prompt | llm | StrOutputParser()\n",
        "        listings_text = chain.invoke({\"num_listings\": num_listings})\n",
        "\n",
        "        self.listings = self._parse_listings(listings_text)\n",
        "        if len(self.listings) < num_listings:\n",
        "            print(f\"Generated only {len(self.listings)} listings, adding fallback samples...\")\n",
        "            self.listings.extend(self._generate_sample_listings(num_listings - len(self.listings)))\n",
        "\n",
        "        print(f\"Total listings generated: {len(self.listings)}\")\n",
        "\n",
        "    def _parse_listings(self, text):\n",
        "        \"\"\"Parse LLM-generated listings\"\"\"\n",
        "        pattern = r\"--- LISTING START ---\\s*(.*?)\\s*--- LISTING END ---\"\n",
        "        raw_listings = re.findall(pattern, text, re.DOTALL)\n",
        "        parsed = []\n",
        "\n",
        "        for listing in raw_listings:\n",
        "            try:\n",
        "                fields = {\n",
        "                    \"neighborhood\": r\"Neighborhood:\\s*(.*?)(?=\\s*\\n)\",\n",
        "                    \"price\": r\"Price:\\s*(.*?)(?=\\s*\\n)\",\n",
        "                    \"bedrooms\": r\"Bedrooms:\\s*(.*?)(?=\\s*\\n)\",\n",
        "                    \"bathrooms\": r\"Bathrooms:\\s*(.*?)(?=\\s*\\n)\",\n",
        "                    \"house_size\": r\"House Size:\\s*(.*?)(?=\\s*\\n)\",\n",
        "                    \"description\": r\"Description:\\s*(.*?)(?=\\s*\\n\\s*Neighborhood Description:)\",\n",
        "                    \"neighborhood_description\": r\"Neighborhood Description:\\s*(.*)$\"\n",
        "                }\n",
        "                listing_dict = {\"id\": str(uuid.uuid4())}\n",
        "\n",
        "                for key, regex in fields.items():\n",
        "                    match = re.search(regex, listing, re.DOTALL)\n",
        "                    if match:\n",
        "                        listing_dict[key] = match.group(1).strip()\n",
        "                    else:\n",
        "                        raise ValueError(f\"Missing {key}\")\n",
        "\n",
        "                parsed.append(listing_dict)\n",
        "            except Exception as e:\n",
        "                print(f\"Parsing error: {e}\")\n",
        "                continue\n",
        "\n",
        "        return parsed\n",
        "\n",
        "    def _generate_sample_listings(self, num):\n",
        "        \"\"\"Fallback sample listings\"\"\"\n",
        "        sample = {\n",
        "            \"id\": str(uuid.uuid4()),\n",
        "            \"neighborhood\": \"Pine Valley\",\n",
        "            \"price\": \"$650,000\",\n",
        "            \"bedrooms\": \"4\",\n",
        "            \"bathrooms\": \"3\",\n",
        "            \"house_size\": \"2,800 sqft\",\n",
        "            \"description\": \"Modern 4-bed home with open floor plan, gourmet kitchen with island, and master suite with spa-like bath. Features smart home tech and a landscaped backyard.\",\n",
        "            \"neighborhood_description\": \"Pine Valley offers suburban peace with top schools, parks, and easy highway access. Close to shops and dining.\"\n",
        "        }\n",
        "        samples = []\n",
        "        for i in range(num):\n",
        "            new_sample = sample.copy()\n",
        "            new_sample[\"id\"] = str(uuid.uuid4())\n",
        "            new_sample[\"neighborhood\"] = f\"{sample['neighborhood']} {i+1}\"\n",
        "            new_sample[\"price\"] = f\"${650000 + i*50000}\"\n",
        "            samples.append(new_sample)\n",
        "        return samples\n",
        "\n",
        "    def save_listings(self):\n",
        "        \"\"\"Save listings to JSON and CSV\"\"\"\n",
        "        # Save as JSON\n",
        "        with open(\"listings.json\", \"w\") as f:\n",
        "            json.dump(self.listings, f, indent=2)\n",
        "        print(\"Saved listings to listings.json\")\n",
        "\n",
        "        # Save as CSV\n",
        "        with open(\"listings.csv\", \"w\", newline=\"\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=self.listings[0].keys())\n",
        "            writer.writeheader()\n",
        "            writer.writerows(self.listings)\n",
        "        print(\"Saved listings to listings.csv\")\n",
        "\n",
        "# Generate and save listings\n",
        "print(\"Generating listings...\")\n",
        "generator = ListingGenerator()\n",
        "generator.generate_listings(100)\n",
        "generator.save_listings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1rHiT_3fYmK",
        "outputId": "7cc2fb20-34a5-4bac-c644-ad46f3e2ed2d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating listings...\n",
            "Generated only 0 listings, adding fallback samples...\n",
            "Total listings generated: 100\n",
            "Saved listings to listings.json\n",
            "Saved listings to listings.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 3: Initialize Vector Database and Load Listings\n",
        "**Purpose:** This cell sets up the vector database and loads the generated listings for semantic search functionality.  \n",
        "**What Happens:**  \n",
        "- Defines a `HomeMatch` class to manage the application's core operations.  \n",
        "- Initializes the class by loading the 10 listings from `listings.json` into memory.  \n",
        "- Resets any existing ChromaDB collection named `real_estate_listings` to ensure a clean slate.  \n",
        "- Creates a new ChromaDB instance with the specified embedding function for vectorizing data.  \n",
        "- Converts each listing into a `Document` object, storing the full listing as JSON in `page_content` and key metadata (excluding descriptions) separately.  \n",
        "- Adds these documents to the ChromaDB collection, enabling semantic search capabilities based on embeddings.  \n"
      ],
      "metadata": {
        "id": "fxPqvd_tmnhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HomeMatch:\n",
        "    def __init__(self, listings_file=\"listings.json\"):\n",
        "        self.listings = self._load_listings(listings_file)\n",
        "        try:\n",
        "            client.delete_collection(collection_name)\n",
        "        except:\n",
        "            pass\n",
        "        self.db = Chroma(\n",
        "            client=client,\n",
        "            collection_name=collection_name,\n",
        "            embedding_function=embeddings\n",
        "        )\n",
        "\n",
        "    def _load_listings(self, filename):\n",
        "        \"\"\"Load listings from JSON file\"\"\"\n",
        "        with open(filename, \"r\") as f:\n",
        "            listings = json.load(f)\n",
        "        print(f\"Loaded {len(listings)} listings from {filename}\")\n",
        "        return listings\n",
        "\n",
        "    def store_listings_in_vector_db(self):\n",
        "        \"\"\"Store listings in ChromaDB\"\"\"\n",
        "        if not self.listings:\n",
        "            print(\"No listings to store!\")\n",
        "            return\n",
        "\n",
        "        documents = [Document(\n",
        "            page_content=json.dumps(listing),\n",
        "            metadata={k: v for k, v in listing.items() if k != \"description\" and k != \"neighborhood_description\"}\n",
        "        ) for listing in self.listings]\n",
        "\n",
        "        # Pass the Document objects directly, not their page_content\n",
        "        self.db.add_documents(documents=documents)\n",
        "        print(f\"Stored {len(documents)} listings in vector DB\")\n",
        "\n",
        "# Initialize HomeMatch and store listings\n",
        "print(\"\\nInitializing HomeMatch and storing listings...\")\n",
        "app = HomeMatch(\"listings.json\")\n",
        "app.store_listings_in_vector_db()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCJO3T-ofucU",
        "outputId": "f0ede6c5-dab9-4831-c6ff-750065254a5c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initializing HomeMatch and storing listings...\n",
            "Loaded 100 listings from listings.json\n",
            "Stored 100 listings in vector DB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 4: Collect and Process Buyer Preferences\n",
        "**Purpose:** This cell collects buyer preferences and transforms them into a semantic search query.  \n",
        "**What Happens:**  \n",
        "- Defines `get_buyer_preferences` to simulate user input with hardcoded preferences (e.g., 3 bedrooms, quiet neighborhood, specific amenities) as a dictionary of question-answer pairs.  \n",
        "- Prints the collected preferences for visibility.  \n",
        "- Defines `process_buyer_preferences` to use the LLM to convert these preferences into a concise search query (under 100 words), leveraging natural language understanding.  \n",
        "- Passes the preferences to the LLM via a prompt, parses the output, and prints the resulting query.  \n",
        "- Executes both functions to prepare the query for the next step.  \n"
      ],
      "metadata": {
        "id": "Lhz3xJ3bms37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_buyer_preferences():\n",
        "    \"\"\"Collect and return buyer preferences\"\"\"\n",
        "    questions = [\n",
        "        \"How big do you want your house to be?\",\n",
        "        \"What are 3 most important things for you in choosing this property?\",\n",
        "        \"Which amenities would you like?\",\n",
        "        \"Which transportation options are important to you?\",\n",
        "        \"How urban do you want your neighborhood to be?\"\n",
        "    ]\n",
        "\n",
        "    answers = [\n",
        "        \"A comfortable three-bedroom house with a spacious kitchen and a cozy living room.\",\n",
        "        \"A quiet neighborhood, good local schools, and convenient shopping options.\",\n",
        "        \"A backyard for gardening, a two-car garage, and a modern, energy-efficient heating system.\",\n",
        "        \"Easy access to a reliable bus line, proximity to a major highway, and bike-friendly roads.\",\n",
        "        \"A balance between suburban tranquility and access to urban amenities like restaurants and theaters.\"\n",
        "    ]\n",
        "\n",
        "    preferences = dict(zip(questions, answers))\n",
        "    print(\"Buyer preferences collected:\")\n",
        "    for q, a in preferences.items():\n",
        "        print(f\"{q}: {a}\")\n",
        "    return preferences\n",
        "\n",
        "def process_buyer_preferences(preferences):\n",
        "    \"\"\"Convert preferences to a search query\"\"\"\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Convert these preferences into a concise search query (under 100 words):\n",
        "        {preferences}\"\"\"\n",
        "    )\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    query = chain.invoke({\"preferences\": \"\\n\".join(f\"{q}: {a}\" for q, a in preferences.items())})\n",
        "    print(f\"Generated search query: {query}\")\n",
        "    return query\n",
        "\n",
        "# Collect and process preferences\n",
        "print(\"\\nCollecting buyer preferences...\")\n",
        "preferences = get_buyer_preferences()\n",
        "print(\"\\nProcessing preferences...\")\n",
        "query = process_buyer_preferences(preferences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKG0DOVqfxFo",
        "outputId": "c3911dab-f332-4a6d-ed0e-1600464c1723"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting buyer preferences...\n",
            "Buyer preferences collected:\n",
            "How big do you want your house to be?: A comfortable three-bedroom house with a spacious kitchen and a cozy living room.\n",
            "What are 3 most important things for you in choosing this property?: A quiet neighborhood, good local schools, and convenient shopping options.\n",
            "Which amenities would you like?: A backyard for gardening, a two-car garage, and a modern, energy-efficient heating system.\n",
            "Which transportation options are important to you?: Easy access to a reliable bus line, proximity to a major highway, and bike-friendly roads.\n",
            "How urban do you want your neighborhood to be?: A balance between suburban tranquility and access to urban amenities like restaurants and theaters.\n",
            "\n",
            "Processing preferences...\n",
            "Generated search query: Here is a concise search query based on the provided preferences:\n",
            "\n",
            "\"3 bedroom house for sale in quiet neighborhood with good schools, convenient shopping, and bus line access. Must have backyard, 2-car garage, and modern heating system. Prefer suburban area with easy access to urban amenities, bike-friendly roads, and proximity to major highway.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 5: Search and Personalize Listings\n",
        "**Purpose:** This cell performs a semantic search on the vector database and generates personalized listing descriptions based on buyer preferences.  \n",
        "**What Happens:**  \n",
        "- Defines `search_listings` to query the ChromaDB collection using the search query from Part 4, retrieving the top 3 matching listings based on semantic similarity.  \n",
        "- Extracts the listing data from the search results by parsing the JSON `page_content` of each `Document`.  \n",
        "- Defines `personalize_listing` to use the LLM to rewrite each matched listing’s description, emphasizing features that align with the buyer’s preferences while preserving factual details.  \n",
        "- Formats the personalized output with a creative title and a \"Why This Is Your Perfect Match\" section with 3 reasons.  \n",
        "- Executes the search and personalization, printing the results for each of the 3 matches.  \n"
      ],
      "metadata": {
        "id": "kiDlevkDmxvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_listings(query, k=3):\n",
        "    \"\"\"Search for matching listings\"\"\"\n",
        "    results = app.db.similarity_search(query, k=k)\n",
        "    matches = [json.loads(r.page_content) for r in results]\n",
        "    print(f\"Found {len(matches)} matching listings\")\n",
        "    return matches\n",
        "\n",
        "def personalize_listing(listing, preferences):\n",
        "    \"\"\"Generate personalized description\"\"\"\n",
        "    prompt = PromptTemplate.from_template(\n",
        "        \"\"\"Original listing:\n",
        "        {listing}\n",
        "\n",
        "        Buyer preferences:\n",
        "        {preferences}\n",
        "\n",
        "        Create a personalized description:\n",
        "        # [Creative Title]\n",
        "        [300-400 character description emphasizing buyer preferences]\n",
        "        ## Why This Is Your Perfect Match\n",
        "        - [Reason 1]\n",
        "        - [Reason 2]\n",
        "        - [Reason 3]\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return chain.invoke({\n",
        "        \"listing\": json.dumps(listing),\n",
        "        \"preferences\": \"\\n\".join(f\"{q}: {a}\" for q, a in preferences.items())\n",
        "    })\n",
        "\n",
        "# Search and personalize listings\n",
        "print(\"\\nSearching listings...\")\n",
        "matches = search_listings(query)\n",
        "\n",
        "print(\"\\nPersonalizing results...\")\n",
        "for i, match in enumerate(matches, 1):\n",
        "    print(f\"\\nMatch {i}:\")\n",
        "    print(personalize_listing(match, preferences))\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzPCAL7Pf006",
        "outputId": "9fe46b21-e1d3-4ed6-fab6-7d6b7d144c2a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Searching listings...\n",
            "Found 3 matching listings\n",
            "\n",
            "Personalizing results...\n",
            "\n",
            "Match 1:\n",
            "Here is a personalized description based on the buyer's preferences:\n",
            "\n",
            "# **Suburban Serenity with Modern Convenience**\n",
            "\n",
            "Escape to this stunning 4-bedroom retreat in Pine Valley, boasting a spacious kitchen, cozy living room, and master suite with spa-like bath. Enjoy a quiet neighborhood with top schools, parks, and easy highway access.\n",
            "\n",
            "## Why This Is Your Perfect Match\n",
            "- **Quiet Neighborhood**: Pine Valley offers suburban peace, perfect for a comfortable and relaxing lifestyle.\n",
            "- **Convenient Shopping**: Easy access to shops and dining, ensuring you're never far from what you need.\n",
            "- **Modern Amenities**: This energy-efficient home features smart home tech, a landscaped backyard for gardening, and a two-car garage for added convenience.\n",
            "--------------------------------------------------\n",
            "\n",
            "Match 2:\n",
            "Here is a personalized description tailored to the buyer's preferences:\n",
            "\n",
            "# Serene Suburban Oasis\n",
            "\n",
            "Escape to a peaceful retreat in Pine Valley 54, where suburban tranquility meets urban convenience! Enjoy a spacious 4-bed home with open floor plan, gourmet kitchen, and master suite with spa-like bath, perfect for a comfortable lifestyle.\n",
            "\n",
            "## Why This Is Your Perfect Match\n",
            "- **Quiet Neighborhood**: Pine Valley offers a serene atmosphere, perfect for those seeking a peaceful retreat.\n",
            "- **Good Local Schools**: Top schools are nearby, ensuring a great education for your family.\n",
            "- **Convenient Shopping**: Easy access to shops and dining, with reliable bus lines and bike-friendly roads for a hassle-free commute.\n",
            "--------------------------------------------------\n",
            "\n",
            "Match 3:\n",
            "Here is a personalized description based on the buyer's preferences:\n",
            "\n",
            "# **Serenity Meets Convenience**\n",
            "\n",
            "Escape to a peaceful retreat in Pine Valley 39, where suburban tranquility meets urban accessibility. This modern 4-bed home boasts a spacious kitchen, cozy living room, and a serene backyard perfect for gardening.\n",
            "\n",
            "## Why This Is Your Perfect Match\n",
            "- **Quiet Neighborhood**: Enjoy the peace and quiet of Pine Valley, with top-rated schools and easy access to parks.\n",
            "- **Convenient Shopping**: Stay close to shops, dining, and major highways, with easy access to reliable bus lines and bike-friendly roads.\n",
            "- **Energy-Efficient Comfort**: Relax in your modern, energy-efficient home, complete with a two-car garage and smart home tech.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MuAk8C4gFdd"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}